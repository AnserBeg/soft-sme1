#!/usr/bin/env ts-node

import fs from 'fs';
import path from 'path';
import { Pool } from 'pg';

interface AgentEventRow {
  source: string;
  event_type: string;
  status: string | null;
  tool: string | null;
  error_message: string | null;
  metadata: any;
  occurred_at: string;
}

interface FailureSummary {
  signature: string;
  occurrences: number;
  sampleError?: string | null;
}

const SAMPLE_DATA_PATH = path.resolve(
  __dirname,
  '..',
  '..',
  'docs',
  'ai-assistant',
  'data',
  'agent_event_logs_sample.json'
);

const REPORT_OUTPUT_PATH = path.resolve(
  __dirname,
  '..',
  '..',
  'docs',
  'ai-assistant',
  'reports',
  'phase0-failure-audit.md'
);

const DAYS = Number(process.argv[2] ?? 30);

async function fetchEvents(pool: Pool): Promise<AgentEventRow[]> {
  const query = `
    SELECT source, event_type, status, tool, error_message, metadata, occurred_at
    FROM agent_event_logs
    WHERE occurred_at >= NOW() - INTERVAL '${DAYS} days'
      AND (
        (source = 'orchestrator' AND event_type IN ('routing_miss', 'tool_invocation', 'tool_unavailable'))
        OR (source = 'python_agent' AND event_type = 'tool_failure')
      )
  `;

  const result = await pool.query(query);
  return result.rows as AgentEventRow[];
}

function loadSampleData(): AgentEventRow[] {
  if (!fs.existsSync(SAMPLE_DATA_PATH)) {
    throw new Error('Sample analytics dataset is missing.');
  }
  const raw = fs.readFileSync(SAMPLE_DATA_PATH, 'utf-8');
  return JSON.parse(raw) as AgentEventRow[];
}

function groupFailures(rows: AgentEventRow[]): {
  routingMisses: FailureSummary[];
  pythonFailures: FailureSummary[];
} {
  const routingAggregate = new Map<string, FailureSummary>();
  const pythonAggregate = new Map<string, FailureSummary>();

  for (const row of rows) {
    if (row.source === 'orchestrator' && row.event_type === 'routing_miss') {
      const fallback = row.metadata?.fallback ?? 'unknown';
      const signature = `fallback=${fallback}`;
      const entry = routingAggregate.get(signature) ?? {
        signature,
        occurrences: 0,
        sampleError: row.error_message,
      };
      entry.occurrences += 1;
      routingAggregate.set(signature, entry);
      continue;
    }

    if (row.source === 'orchestrator' && row.event_type === 'tool_unavailable') {
      const signature = `missing_tool:${row.tool ?? row.metadata?.tool ?? 'unknown'}`;
      const entry = routingAggregate.get(signature) ?? {
        signature,
        occurrences: 0,
        sampleError: row.error_message,
      };
      entry.occurrences += 1;
      routingAggregate.set(signature, entry);
      continue;
    }

    if (row.source === 'python_agent' && row.event_type === 'tool_failure') {
      const stage = row.metadata?.stage ? String(row.metadata.stage) : 'unknown';
      const tool = row.tool ?? row.metadata?.tool ?? 'unspecified';
      const signature = `${tool}:${stage}`;
      const entry = pythonAggregate.get(signature) ?? {
        signature,
        occurrences: 0,
        sampleError: row.error_message,
      };
      entry.occurrences += 1;
      if (!entry.sampleError && row.error_message) {
        entry.sampleError = row.error_message;
      }
      pythonAggregate.set(signature, entry);
    }
  }

  const routingMisses = Array.from(routingAggregate.values()).sort((a, b) => b.occurrences - a.occurrences);
  const pythonFailures = Array.from(pythonAggregate.values()).sort((a, b) => b.occurrences - a.occurrences);

  return { routingMisses, pythonFailures };
}

function buildMarkdown(
  routingMisses: FailureSummary[],
  pythonFailures: FailureSummary[],
  source: 'database' | 'sample'
): string {
  const lines: string[] = [];
  lines.push(`# Agent Failure Audit (last ${DAYS} days)`);
  lines.push('');
  lines.push(`_Data source: ${source === 'database' ? 'Postgres analytics warehouse' : 'sample dataset'}_`);
  lines.push('');

  lines.push('## Routing misses');
  if (routingMisses.length === 0) {
    lines.push('No routing misses recorded during the observation window.');
  } else {
    lines.push('| Signature | Occurrences | Sample error |');
    lines.push('| --- | ---: | --- |');
    for (const miss of routingMisses) {
      lines.push(`| ${miss.signature} | ${miss.occurrences} | ${miss.sampleError ?? ''} |`);
    }
  }

  lines.push('');
  lines.push('## Python agent tool failures');
  if (pythonFailures.length === 0) {
    lines.push('No Python agent tool failures captured in the analytics logs.');
  } else {
    lines.push('| Tool & stage | Occurrences | Sample error |');
    lines.push('| --- | ---: | --- |');
    for (const failure of pythonFailures) {
      lines.push(`| ${failure.signature} | ${failure.occurrences} | ${failure.sampleError ?? ''} |`);
    }
  }

  lines.push('');
  lines.push('Generated by `scripts/audit-agent-failures.ts`.');

  return lines.join('\n');
}

async function main() {
  let pool: Pool | null = null;
  let rows: AgentEventRow[] = [];
  let source: 'database' | 'sample' = 'database';

  try {
    pool = new Pool();
    rows = await fetchEvents(pool);
  } catch (error) {
    console.warn('Falling back to sample analytics dataset:', (error as Error).message);
    rows = loadSampleData();
    source = 'sample';
  } finally {
    await pool?.end();
  }

  const { routingMisses, pythonFailures } = groupFailures(rows);

  fs.mkdirSync(path.dirname(REPORT_OUTPUT_PATH), { recursive: true });
  const markdown = buildMarkdown(routingMisses, pythonFailures, source);
  fs.writeFileSync(REPORT_OUTPUT_PATH, markdown, 'utf-8');

  console.log(markdown);
}

main().catch((error) => {
  console.error('Failed to audit agent failures', error);
  process.exit(1);
});

